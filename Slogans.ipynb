{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import *\n",
    "import requests\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get('http://www.textart.ru/database/slogan/list-advertising-slogans.html')\n",
    "tree = html.fromstring(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subcategories_links = tree.xpath(\"//div/select/option/@value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict['dupa'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = re.compile(\n",
    "        r'^(?:http|ftp)s?://' # http:// or https://\n",
    "        r'(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\\.)+(?:[A-Z]{2,6}\\.?|[A-Z0-9-]{2,}\\.?)|' #domain...\n",
    "        r'localhost|' #localhost...\n",
    "        r'\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3})' # ...or ip\n",
    "        r'(?::\\d+)?' # optional port\n",
    "        r'(?:/?|[/?]\\S+)$', re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_slogans_from_page(tree):\n",
    "    slogan_dict = {}\n",
    "    for paragraph in tree.xpath(\"//p[contains(@class, 'paragraf')]\"):\n",
    "        brand = paragraph.text\n",
    "        slogan = paragraph.find(\"span\")\n",
    "        if brand is None or slogan is None:\n",
    "            continue\n",
    "        \n",
    "        final_slogan = slogan.text.strip()\n",
    "        final_slogan = re.sub(\"\\n+\", \"\", final_slogan)\n",
    "        final_slogan = re.sub(\"^\\s+\", \"\", final_slogan)\n",
    "        final_slogan = re.sub(\"\\s+\", \" \", final_slogan)\n",
    "        slogan_dict[brand] = final_slogan\n",
    "    return slogan_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category_name(tree_element):\n",
    "    cat = tree_element[-1] \\\n",
    "                        .strip().removesuffix(' slogans.') \\\n",
    "                        .removesuffix(' slogans') \\\n",
    "                        .removesuffix(' advertising') \\\n",
    "                        .removeprefix(\"Database of slogans. \") \\\n",
    "                        .removeprefix(\"Advertising slogans for \") \\\n",
    "                        .removesuffix(\".\") \\\n",
    "                        .capitalize()\n",
    "    cat = re.sub(\"Database\\s+ of slogans\\.\\s+.*?\", \"\", cat)\n",
    "    cat = re.sub(\"\\n\", \"\", cat)\n",
    "    cat = re.sub(\"\\s+\", \" \", cat)\n",
    "    return cat.capitalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_link(link):\n",
    "    regex = re.compile(\n",
    "        r'^(?:http|ftp)s?://' # http:// or https://\n",
    "        r'(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\\.)+(?:[A-Z]{2,6}\\.?|[A-Z0-9-]{2,}\\.?)|' #domain...\n",
    "        r'localhost|' #localhost...\n",
    "        r'\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3})' # ...or ip\n",
    "        r'(?::\\d+)?' # optional port\n",
    "        r'(?:/?|[/?]\\S+)$', re.IGNORECASE)\n",
    "    return re.match(regex, link) is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slogans = {}\n",
    "for link in subcategories_links[1:4]:\n",
    "    \n",
    "    if re.match(regex, link) is None:\n",
    "        continue\n",
    "        \n",
    "    page = requests.get(link)\n",
    "    tree = html.fromstring(page.content)\n",
    "    \n",
    "    if not tree.xpath(\"//h1/font/text()\"):\n",
    "        continue\n",
    "    \n",
    "    #print(tree.xpath(\"//h1/font/text()\")[0])\n",
    "#    category = re.search(\"Database\\s+?\\n+\\s+of slogans. (.*)\\s+\", tree.xpath(\"//h1/font/text()\")[0].strip() \\\n",
    "#                         .removesuffix(\"advertising slogans.\"), re.MULTILINE).groups()[0]\n",
    "    category = get_category_name(tree.xpath(\"//h1/font/text()\"))\n",
    "    \n",
    "    slogans[category] = {}\n",
    "    \n",
    "    for sublink in tree.xpath(\"//div/select/option/@value\"):\n",
    "        if re.match(regex, sublink) is None:\n",
    "            continue\n",
    "        \n",
    "        page = requests.get(sublink)\n",
    "        tree = html.fromstring(page.content)\n",
    "        subcategory = get_category_name(tree.xpath(\"//h1/text()\"))\n",
    "        \n",
    "        \n",
    "        if subcategory == \"\":\n",
    "            print(sublink)\n",
    "            subcategory = get_category_name(tree.xpath(\"//h1/font/text()\"))\n",
    "\n",
    "            slogans[category][subcategory] = {}\n",
    "            for sub_sublink in tree.xpath(\"//div/select/option/@value\"):\n",
    "                if re.match(regex, sub_sublink) is None:\n",
    "                    continue\n",
    "                \n",
    "                page = requests.get(sub_sublink)\n",
    "                tree = html.fromstring(page.content)\n",
    "                sub_subcategory = get_category_name(tree.xpath(\"//h1/font/text()\"))\n",
    "                print(sub_subcategory)\n",
    "                if not sub_subcategory:\n",
    "                    print(\"Bazinga\")\n",
    "                    continue\n",
    "                \n",
    "                \n",
    "                slogans[category][subcategory][sub_subcategory] = {}\n",
    "                slogans_dict = get_slogans_from_page(tree)\n",
    "                slogans[category][subcategory][sub_subcategory] = slogans_dict\n",
    "        else:\n",
    "\n",
    "            #print(category, subcategory)\n",
    "            \n",
    "            slogans[category][subcategory] = {}\n",
    "            slogans_dict = get_slogans_from_page(tree)\n",
    "        \n",
    "        #more than 1 page\n",
    "        for additional_page in tree.xpath(\"//font/a/@href\"):\n",
    "            page = requests.get(additional_page)\n",
    "            tree = html.fromstring(page.content)\n",
    "            slogans_dict += get_slogans_from_page(tree)\n",
    "            \n",
    "        slogans[category][subcategory] = slogans_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get('http://www.textart.ru/database/slogan/list-advertising-slogans.html')\n",
    "tree = html.fromstring(page.content)\n",
    "get_all_links(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_links(tree):\n",
    "    slogans = {}\n",
    "    for link in tree.xpath(\"//div/select/option/@value\"):\n",
    "        print(verify_link(link), link)\n",
    "        if not verify_link(link):\n",
    "            continue\n",
    "        \n",
    "        page = requests.get(link)\n",
    "        tree = html.fromstring(page.content)\n",
    "        category = get_category_name(tree.xpath(\"//h1/text()\"))\n",
    "            \n",
    "        if category == \"\":\n",
    "            print(verify_link(link), link)\n",
    "            continue\n",
    "        \n",
    "        slogans[category] = get_slogans_from_page(tree)\n",
    "        #slogans_dict = get_slogans_from_page(tree)\n",
    "        \n",
    "        #more than 1 page\n",
    "        for additional_page in tree.xpath(\"//font/a/@href\"):\n",
    "            page = requests.get(additional_page)\n",
    "            tree = html.fromstring(page.content)\n",
    "            slogans = {**slogans, **get_slogans_from_page(tree)}\n",
    "    return slogans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_slogan():\n",
    "    return np.random.choice(list(slogans['Apparel']['Beachwear & swimwear'].values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(slogans['Apparel']['Beachwear & swimwear'].values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_random_slogan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subcategory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"slogan_dict.json\", \"w\") as fp:\n",
    "    json.dump(slogan_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
